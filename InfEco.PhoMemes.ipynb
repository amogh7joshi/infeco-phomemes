{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training-PhoMemes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "67f48de73d384bb69fe75e5858ab531f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1601198dc6ad449ba9f06c5448e4cb68",
              "IPY_MODEL_9541eb4895b54baf8ad409bd24b2557c",
              "IPY_MODEL_172d7fea325843728dd71d6429aa19ab"
            ],
            "layout": "IPY_MODEL_ed74296730f14f9db94a44db1f5a7085"
          }
        },
        "1601198dc6ad449ba9f06c5448e4cb68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1be4431b23584b0296e10aadbdd71a45",
            "placeholder": "​",
            "style": "IPY_MODEL_dab158b2693b4969be3476651585efb4",
            "value": "Generating Average Embeddings: 100%"
          }
        },
        "9541eb4895b54baf8ad409bd24b2557c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81131ac9f0784292a28bd954dd8c6a82",
            "max": 24,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd3cdd97d5fe436cbaea90ab03aeb6bc",
            "value": 24
          }
        },
        "172d7fea325843728dd71d6429aa19ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aff39b4a3b164b3e91f1f78dca255607",
            "placeholder": "​",
            "style": "IPY_MODEL_7666dab312794d8c8a57f4a2012a2c2e",
            "value": " 24/24 [00:01&lt;00:00, 29.59it/s]"
          }
        },
        "ed74296730f14f9db94a44db1f5a7085": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1be4431b23584b0296e10aadbdd71a45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dab158b2693b4969be3476651585efb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81131ac9f0784292a28bd954dd8c6a82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd3cdd97d5fe436cbaea90ab03aeb6bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aff39b4a3b164b3e91f1f78dca255607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7666dab312794d8c8a57f4a2012a2c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PhoMemes Data Challenge\n",
        "\n",
        "Source code for the submission by `Inf.Eco`."
      ],
      "metadata": {
        "id": "XbVu5uztPsxV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "StjFeFuemt3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q scikit-learn==0.22.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RpKsLWIuCYT",
        "outputId": "0e28669e-7c48-4167-8566-074810871033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.1 MB 4.7 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.2 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsksG_pKLrXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b092966-25ed-4945-b18d-1eef1a28f6af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Mount Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up Training Data\n",
        "\n",
        "Extract the training data from the provided files."
      ],
      "metadata": {
        "id": "7PDeG60IgnRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data path.\n",
        "data_dir = \"/content/drive/Shareddrives/Inf.Eco.UMD/DATASETS/authenticity.training\"\n",
        "\n",
        "# Unzip all files.\n",
        "out_dir = \"/content/drive/Shareddrives/Inf.Eco.UMD/DATASETS/PhoMemesTraining\"\n",
        "if os.path.exists(out_dir): # Change to not os.path.exists\n",
        "  os.makedirs(out_dir, exist_ok = True)\n",
        "  for file in glob.glob(os.path.join(data_dir, \"*.zip\")):\n",
        "    !unzip -qq $file -d $out_dir\n",
        "else:\n",
        "  print(f\"Directory {out_dir} already exists, skipping unzip.\")"
      ],
      "metadata": {
        "id": "7cMqZ05Ygswt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Features\n",
        "\n",
        "Extract feature embeddings for each of the images from ResNet50, then get their corresponding clusters."
      ],
      "metadata": {
        "id": "iQzZeUVFnIn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all of the image paths.\n",
        "image_files = glob.glob(os.path.join(out_dir, '**/*.jpg'), recursive = True) + \\\n",
        "              glob.glob(os.path.join(out_dir, '**/*.png'), recursive = True) + \\\n",
        "              glob.glob(os.path.join(out_dir, '**/*.jpeg'), recursive = True)\n",
        "\n",
        "# Maintain the same order every time.\n",
        "image_files = sorted(image_files)\n",
        "print(f\"Got {len(image_files)} image files.\")\n",
        "\n",
        "# Save the images for the future.\n",
        "with open('/content/drive/Shareddrives/Inf.Eco/PROJECTS/ImageDeduplication/Data/PhoMemesData/images.pickle', 'wb') as f:\n",
        "  pickle.dump(image_files, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf6rrecqnWI6",
        "outputId": "de6b0172-e389-46db-84b5-5d300cbc91ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 5223 image files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Feature Extraction\n",
        "\n",
        "Run the ResNet50 feature extraction."
      ],
      "metadata": {
        "id": "pPkPegqxSdjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import ResNet50, VGG19, InceptionV3, EfficientNetB0, DenseNet121"
      ],
      "metadata": {
        "id": "TJDgkP-ySkqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(image_path):\n",
        "  \"\"\"Read and preprocess and image.\"\"\"\n",
        "  # If image paths don't exist, then just skip and move on.\n",
        "  if not os.path.exists(image_path):\n",
        "    return False\n",
        "\n",
        "  # Read the image.\n",
        "  image = cv2.imread(image_path)\n",
        "\n",
        "  # If the image is corrupted or empty, then continue on without doing anything.\n",
        "  if image is None:\n",
        "    print(\"Unusable Image: \" + str(image_path))\n",
        "    return False\n",
        "\n",
        "  # Resize the image.\n",
        "  return cv2.cvtColor(cv2.resize(image, (256, 256)), cv2.COLOR_BGR2RGB)"
      ],
      "metadata": {
        "id": "v36HK6krSn02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_feature_extractor(name = \"resnet50\", input_shape = None):\n",
        "  \"\"\"Constructs a feature extraction model from a pretrained base.\"\"\"\n",
        "  # Select the correct feature extractor.\n",
        "  name = name.lower() \n",
        "  if name == \"resnet50\":\n",
        "    _model_base = ResNet50\n",
        "  elif name == \"vgg19\":\n",
        "    _model_base = VGG19\n",
        "  elif name == \"inceptionv3\":\n",
        "    _model_base = InceptionV3\n",
        "  elif name == \"effnet\":\n",
        "    _model_base = EfficientNetB0\n",
        "  elif name == \"densenet\":\n",
        "    _model_base = DenseNet121\n",
        "  else:\n",
        "    raise ValueError(f\"Received invalid feature extractor base {name}.\")\n",
        "\n",
        "  # Create the input tensor for the model.\n",
        "  input_tensor = Input(shape = (256, 256, 3)) \\\n",
        "                 if input_shape is None else Input(shape = input_shape)\n",
        "  \n",
        "  # Load the feature extractor.\n",
        "  _pretrained_transfer_model = _model_base(\n",
        "  include_top = False, weights = 'imagenet', input_tensor = input_tensor)\n",
        "  # Make the layers non-trainable.\n",
        "  for layer in _pretrained_transfer_model.layers:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  # Perform global average pooling to reduce output layer dimensions.\n",
        "  x = GlobalAveragePooling2D()(_pretrained_transfer_model.output)\n",
        "\n",
        "  # Build the model.\n",
        "  model = Model(input_tensor, x)\n",
        "\n",
        "  # Compile the model.\n",
        "  model.compile(\n",
        "      loss = categorical_crossentropy, \n",
        "      optimizer = Adam()\n",
        "  )\n",
        "\n",
        "  # Return the complete feature extractor base.\n",
        "  return model"
      ],
      "metadata": {
        "id": "j60jB1GoSrA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = build_feature_extractor(name = 'resnet50')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMdUU9HZSvoD",
        "outputId": "e14912c3-292d-4794-9e83-54295cd17d39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new holder list.\n",
        "final_image_paths = []\n",
        "\n",
        "# Iterate over the list and select batches of images.\n",
        "for indx in range(0, len(image_files), 50):\n",
        "  try: # Try adding a batch of 50 images.\n",
        "    final_image_paths.append(image_files[indx: indx + 50])\n",
        "  except IndexError: # Otherwise, just the remaining ones.\n",
        "    final_image_paths.append(image_files[indx:])"
      ],
      "metadata": {
        "id": "iHkptyK4SxFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "def extract_features(image_paths, feature_extractor):\n",
        "  \"\"\"Conducts the actual feature extraction on images.\"\"\"\n",
        "  image_features = np.zeros(shape = (sum(len(i) for i in image_paths), feature_extractor.output_shape[-1]))\n",
        "\n",
        "  # Iterate over all of the image batches.\n",
        "  print(\"Starting Extraction\")\n",
        "  for indx, image_batch in enumerate(tqdm(image_paths, desc = \"Generating All Embeddings\")):\n",
        "    # Create an image batch.\n",
        "    batch = np.zeros(shape = (len(image_batch), 256, 256, 3))\n",
        "    for i, image_path in enumerate(tqdm(image_batch, leave = False)):\n",
        "      batch[i] = load_image(image_path)\n",
        "      if np.sum(batch[i]) == 0:\n",
        "        print(\"Image is Zero: \" + image_path)\n",
        "        print(batch[i]) \n",
        "\n",
        "    # Extract image features.\n",
        "    feature_vector = feature_extractor.predict(batch)\n",
        "\n",
        "    # Add features to feature array.\n",
        "    if len(image_batch) == 50:\n",
        "      image_features[indx * len(image_batch): (indx + 1) * len(image_batch)] = feature_vector\n",
        "    else:\n",
        "      image_features[indx * 50:] = feature_vector\n",
        "  \n",
        "  # Return the compiled feature vectors.\n",
        "  return image_features"
      ],
      "metadata": {
        "id": "AV9R9WqcS6Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conduct the feature extraction.\n",
        "feature_vectors = extract_features(final_image_paths, feature_extractor)\n",
        "\n",
        "# Create the path to save the features to.\n",
        "base_save_path = f'/content/drive/Shareddrives/Inf.Eco/PROJECTS/ImageDeduplication/Data/PhoMemesData'\n",
        "\n",
        "# Save the features to a pickle file.\n",
        "with open(os.path.join(base_save_path, f'embeddings.pickle'), 'wb') as file:\n",
        "  pickle.dump(feature_vectors, file)"
      ],
      "metadata": {
        "id": "vWA9fMrYS8Kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clustering\n",
        "\n",
        "Run the clustering model on the output embeddings."
      ],
      "metadata": {
        "id": "zxbfMeLYotOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data base path.\n",
        "base_save_path = f'/content/drive/Shareddrives/Inf.Eco/PROJECTS/ImageDeduplication/Data/PhoMemesData'\n",
        "\n",
        "# Load the embeddings.\n",
        "with open(os.path.join(base_save_path, f'embeddings.pickle'), 'rb') as file:\n",
        "  embeddings = pickle.load(file)\n",
        "\n",
        "# Load the clustering model.\n",
        "with open(\n",
        "    '/content/drive/Shareddrives/Inf.Eco/PROJECTS/ImageDeduplication/Data/Models/resnet50_kmeans.pickle', 'rb') as f:\n",
        "  kmeans = pickle.load(f)\n",
        "\n",
        "# Run the KMeans model.\n",
        "clusters = kmeans.predict(embeddings)\n",
        "\n",
        "# Save the clusters.\n",
        "with open(os.path.join(base_save_path, 'clusters.pickle'), 'wb') as f:\n",
        "  pickle.dump(clusters, f)\n",
        "\n",
        "# Print out information.\n",
        "print(\"Clustering Results:\")\n",
        "np.unique(clusters, return_counts = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMTzJFRwozIE",
        "outputId": "67ed5194-0996-48b9-d207-e8525c0b6505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator KMeans from version 0.22.2.post1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clustering Results:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int32),\n",
              " array([ 534, 1421,  336,  788,  179,  553,  946,  466]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Distributions\n",
        "\n",
        "Constructs a dataframe with the proportions of images in each cluster (for each account)."
      ],
      "metadata": {
        "id": "_gtWAcLWq2rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the images.\n",
        "with open(os.path.join(base_save_path, f'images.pickle'), 'rb') as file:\n",
        "  image_files = pickle.load(file)\n",
        "\n",
        "# Get the unique accounts.\n",
        "import tensorflow as tf\n",
        "images = tf.nest.flatten(image_files)\n",
        "accounts = [os.path.basename(os.path.dirname(i)) for i in image_files]\n",
        "base_accounts = np.array(accounts, copy = True)\n",
        "accounts = np.unique(base_accounts).tolist()\n",
        "clusters = np.array(clusters)\n",
        "\n",
        "# Create a dataframe to store values.\n",
        "df = pd.DataFrame(columns = ('account', 'imgs'))\n",
        "df['account'] = accounts\n",
        "\n",
        "# Iterate over the accounts and get the clusters for each account.\n",
        "num_images = []\n",
        "total_clusters = {k: [] for k in [f'cl_{i}' for i in range(8)]}\n",
        "for account in accounts:\n",
        "  account_clusters = clusters[np.where(base_accounts == account)[0]]\n",
        "  num_images.append(len(account_clusters))\n",
        "  c, counts = np.unique(account_clusters, return_counts = True)\n",
        "  unique_clusters = {f'cl_{i}': value for i, value in zip(c, counts)}\n",
        "  for i in range(8):\n",
        "    unique_clusters.setdefault(f'cl_{i}', 0)\n",
        "  for key, value in unique_clusters.items():\n",
        "    total_clusters[key].append(value)\n",
        "\n",
        "# Update the dataframe.\n",
        "df['imgs'] = num_images\n",
        "for key, value in total_clusters.items():\n",
        "  df[key] = value\n",
        "\n",
        "# Normalize the cluster values.\n",
        "df[[f'cl_{i}' for i in range(0, 8)]] = df[[f'cl_{i}' for i in range(0, 8)]].div(df['imgs'], axis=0)\n",
        "\n",
        "# Drop any campaigns with <15 images.\n",
        "for indx in range(len(df) - 1, -1, -1):\n",
        "  if df.loc[indx]['imgs'] < 15:\n",
        "    df = df.drop([df.index[indx]])\n",
        "\n",
        "# Remove the imgs column entirely.\n",
        "df.drop('imgs', axis = 1)\n",
        "\n",
        "# Save the dataframe to a CSV.\n",
        "df.to_csv(f'/content/drive/Shareddrives/Inf.Eco/PROJECTS/ImageDeduplication/Data/PhoMemesData/normalized_cluster_matrix.csv')\n",
        "\n",
        "# Print out the dataframe.\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "063PtW_6q81V",
        "outputId": "44a8bb41-55b7-4b18-95f1-0549a24806a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    account  imgs      cl_0      cl_1  \\\n",
              "0    03344d094543191571197d6efb6674af-41973    60  0.000000  0.133333   \n",
              "1    0a6f188af411bb222c4cc884a3cc91a1-27538    60  0.000000  0.383333   \n",
              "2    0a71311b53dd86526265d85a30392db7-37378    60  0.000000  0.250000   \n",
              "3     0af984c788a31ce8da0f41afe32fca89-1263    21  0.142857  0.190476   \n",
              "4    0c6b9e8cacc56768aebc380830c33d3b-16211    60  0.050000  0.733333   \n",
              "..                                      ...   ...       ...       ...   \n",
              "115   fc2c22d3dfa89cb63a0e6a6bb7605429-1690    60  0.083333  0.416667   \n",
              "116   fc6d5a19a5d9a898c3920039878ec425-7903    60  0.216667  0.066667   \n",
              "117  fe73da43c2217dbe50b77be23f120364-40972    33  0.393939  0.181818   \n",
              "118  fed825d4a915897839ac41a516b95910-57859    60  0.116667  0.350000   \n",
              "119  fee4164ef10a4973fb163867e4c1a29f-57308    21  0.000000  0.142857   \n",
              "\n",
              "         cl_2      cl_3      cl_4      cl_5      cl_6      cl_7  \n",
              "0    0.116667  0.216667  0.000000  0.016667  0.266667  0.250000  \n",
              "1    0.133333  0.116667  0.000000  0.033333  0.150000  0.183333  \n",
              "2    0.033333  0.283333  0.000000  0.000000  0.433333  0.000000  \n",
              "3    0.095238  0.238095  0.047619  0.142857  0.095238  0.047619  \n",
              "4    0.000000  0.016667  0.000000  0.133333  0.050000  0.016667  \n",
              "..        ...       ...       ...       ...       ...       ...  \n",
              "115  0.033333  0.183333  0.066667  0.066667  0.133333  0.016667  \n",
              "116  0.033333  0.216667  0.000000  0.083333  0.283333  0.100000  \n",
              "117  0.060606  0.181818  0.000000  0.060606  0.000000  0.121212  \n",
              "118  0.066667  0.233333  0.016667  0.083333  0.116667  0.016667  \n",
              "119  0.285714  0.285714  0.190476  0.095238  0.000000  0.000000  \n",
              "\n",
              "[120 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-989c2c44-5647-49c5-b9a6-c26c8ad2fd4c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account</th>\n",
              "      <th>imgs</th>\n",
              "      <th>cl_0</th>\n",
              "      <th>cl_1</th>\n",
              "      <th>cl_2</th>\n",
              "      <th>cl_3</th>\n",
              "      <th>cl_4</th>\n",
              "      <th>cl_5</th>\n",
              "      <th>cl_6</th>\n",
              "      <th>cl_7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>03344d094543191571197d6efb6674af-41973</td>\n",
              "      <td>60</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.116667</td>\n",
              "      <td>0.216667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016667</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0a6f188af411bb222c4cc884a3cc91a1-27538</td>\n",
              "      <td>60</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.383333</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.116667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>0.183333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0a71311b53dd86526265d85a30392db7-37378</td>\n",
              "      <td>60</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.283333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.433333</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0af984c788a31ce8da0f41afe32fca89-1263</td>\n",
              "      <td>21</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.238095</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.047619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0c6b9e8cacc56768aebc380830c33d3b-16211</td>\n",
              "      <td>60</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.016667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>fc2c22d3dfa89cb63a0e6a6bb7605429-1690</td>\n",
              "      <td>60</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.183333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.016667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>fc6d5a19a5d9a898c3920039878ec425-7903</td>\n",
              "      <td>60</td>\n",
              "      <td>0.216667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.216667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.283333</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>fe73da43c2217dbe50b77be23f120364-40972</td>\n",
              "      <td>33</td>\n",
              "      <td>0.393939</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.121212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>fed825d4a915897839ac41a516b95910-57859</td>\n",
              "      <td>60</td>\n",
              "      <td>0.116667</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.016667</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.116667</td>\n",
              "      <td>0.016667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>fee4164ef10a4973fb163867e4c1a29f-57308</td>\n",
              "      <td>21</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-989c2c44-5647-49c5-b9a6-c26c8ad2fd4c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-989c2c44-5647-49c5-b9a6-c26c8ad2fd4c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-989c2c44-5647-49c5-b9a6-c26c8ad2fd4c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation\n",
        "\n",
        "Train and evaluate two models on an 80-20 split of the data."
      ],
      "metadata": {
        "id": "gQ1is6bcpou8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Training/Evaluation Split\n",
        "\n",
        "Generate a 80-20 training/evaluation split. They will be saved separately so that they can be loaded separately."
      ],
      "metadata": {
        "id": "6EGHuFQLres8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data base path.\n",
        "base_save_path = f'/content/drive/Shareddrives/Inf.Eco/PROJECTS/ImageDeduplication/Data/PhoMemesData'\n",
        "\n",
        "# Load the images and embeddings.\n",
        "with open(os.path.join(base_save_path, 'images.pickle'), 'rb') as f:\n",
        "  images = np.array(pickle.load(f))\n",
        "with open(os.path.join(base_save_path, 'embeddings.pickle'), 'rb') as f:\n",
        "  embeddings = pickle.load(f)\n",
        "\n",
        "# Create a vector of accounts and output classifications. To do this, get the\n",
        "# accounts and campaigns. If the campaigns are authentic, give all associated\n",
        "# accounts a value of 0. If they are inauthentic, give all associated accounts\n",
        "# a value of 1. Then, just maintain the account and output vectors.\n",
        "b, d = os.path.basename, os.path.dirname\n",
        "account_meta = np.unique([os.path.join(b(d(d(i))), b(d(i))) for i in images])\n",
        "accounts = [os.path.basename(p) for p in account_meta]\n",
        "campaigns = [os.path.dirname(p) for p in account_meta]\n",
        "outputs = [1 if any(i in campaign for i in ['congress', 'political']) else 0 for campaign in campaigns]\n",
        "\n",
        "# Save the account-campaign mapping.\n",
        "import json\n",
        "with open(os.path.join(base_save_path, 'account_to_campaign'), 'w') as f:\n",
        "  json.dump({a: c for a, c in zip(accounts, campaigns)}, f)\n",
        "\n",
        "# Generate an 80-20 train/evaluation split.\n",
        "from sklearn.model_selection import train_test_split\n",
        "accounts = np.array(accounts)\n",
        "outputs = np.array(outputs)\n",
        "X_train, X_eval, y_train, y_eval = train_test_split(\n",
        "    accounts, outputs, train_size = 0.8, test_size = 0.2, random_state = 129038)\n",
        "\n",
        "# Save the data.\n",
        "with open(os.path.join(base_save_path, 'training.pickle'), 'wb') as f:\n",
        "  pickle.dump((X_train, y_train), f)\n",
        "with open(os.path.join(base_save_path, 'eval.pickle'), 'wb') as f:\n",
        "  pickle.dump((X_eval, y_eval), f)"
      ],
      "metadata": {
        "id": "cairTTm7p1ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model 1\n",
        "\n",
        "Train Model 1, which is on cluster proportions."
      ],
      "metadata": {
        "id": "ylT2IaRSvC-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the training/evaluation accounts.\n",
        "with open(os.path.join(base_save_path, 'training.pickle'), 'rb') as f:\n",
        "  X_train, y_train = pickle.load(f)\n",
        "\n",
        "# Get the cluster proportions from the dataframe.\n",
        "df = pd.read_csv(f'/content/drive/Shareddrives/Inf.Eco/PROJECTS/ImageDeduplication/Data/PhoMemesData/normalized_cluster_matrix.csv')\n",
        "df = df.loc[df['account'].isin(X_train)]\n",
        "cluster_proportions = df[[f'cl_{i}' for i in range(7 + 1)]].values"
      ],
      "metadata": {
        "id": "o-rRQORDvEki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to the data.\n",
        "model = RandomForestClassifier(verbose = 0, random_state = 11823, n_jobs = -1)\n",
        "model.fit(cluster_proportions, y_train)\n",
        "\n",
        "# Save the results.\n",
        "with open('/content/drive/Shareddrives/Inf.Eco/PROJECTS/ImageDeduplication/Data/PhoMemesData/model_1.pickle', 'wb') as f:\n",
        "  pickle.dump(model, f)"
      ],
      "metadata": {
        "id": "CKXm6mPDv2Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model 2\n",
        "\n",
        "Train Model 2, which is on embeddings."
      ],
      "metadata": {
        "id": "XR_6pQosxMQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data base path.\n",
        "base_save_path = f'/content/drive/Shareddrives/Inf.Eco/PROJECTS/ImageDeduplication/Data/PhoMemesData'\n",
        "\n",
        "# Load the images and embeddings.\n",
        "with open(os.path.join(base_save_path, 'images.pickle'), 'rb') as f:\n",
        "  images = np.array(pickle.load(f))\n",
        "with open(os.path.join(base_save_path, 'embeddings.pickle'), 'rb') as f:\n",
        "  embeddings = pickle.load(f)\n",
        "\n",
        "# Load in the training data.\n",
        "with open(os.path.join(base_save_path, 'training.pickle'), 'rb') as f:\n",
        "  X_train, y_train = pickle.load(f)\n",
        "\n",
        "# Create the averaged embeddings per account.\n",
        "averaged_embeddings = []\n",
        "for sample in tqdm(X_train, desc = \"Generating Average Embeddings\"):\n",
        "  e = embeddings[[images.tolist().index(c) for c in [i for i in images if sample in i]]]\n",
        "  averaged_embeddings.append(e.mean(0))\n",
        "X = np.stack(averaged_embeddings)"
      ],
      "metadata": {
        "id": "dr74c7auxQR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to the data.\n",
        "model = RandomForestClassifier(verbose = 0, random_state = 11823, n_jobs = -1)\n",
        "model.fit(X, y_train)\n",
        "\n",
        "# Save the results.\n",
        "with open('/content/drive/Shareddrives/Inf.Eco/PROJECTS/ImageDeduplication/Data/PhoMemesData/model_2.pickle', 'wb') as f:\n",
        "  pickle.dump(model, f)"
      ],
      "metadata": {
        "id": "SidM-ULKqhDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "\n",
        "Run evaluation of a given model on the data."
      ],
      "metadata": {
        "id": "JYGdChsFwAU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the evaluation data.\n",
        "with open(os.path.join(base_save_path, 'eval.pickle'), 'rb') as f:\n",
        "  X_eval, y_eval = pickle.load(f)"
      ],
      "metadata": {
        "id": "jltcFt0AwCmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the inputted model, process the data using any inputted processing function, and then get the predictions."
      ],
      "metadata": {
        "id": "GH1RXY4BwRN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the inputted model.\n",
        "with open('/content/drive/Shareddrives/Inf.Eco/PROJECTS/ImageDeduplication/Data/PhoMemesData/model_2.pickle', 'rb') as f:\n",
        "  model = pickle.load(f)\n",
        "\n",
        "# Process the data with the given processing function.\n",
        "def process_data_model1(data):\n",
        "  df = pd.read_csv(f'/content/drive/Shareddrives/Inf.Eco/PROJECTS/ImageDeduplication/Data/PhoMemesData/normalized_cluster_matrix.csv')\n",
        "  df = df.loc[df['account'].isin(data)]\n",
        "  return df[[f'cl_{i}' for i in range(7 + 1)]].values\n",
        "\n",
        "def process_data_model2(data):\n",
        "  # Load the images and embeddings.\n",
        "  with open(os.path.join(base_save_path, 'images.pickle'), 'rb') as f:\n",
        "    images = np.array(pickle.load(f))\n",
        "  with open(os.path.join(base_save_path, 'embeddings.pickle'), 'rb') as f:\n",
        "    embeddings = pickle.load(f)\n",
        "\n",
        "  # Create the averaged embeddings per account.\n",
        "  averaged_embeddings = []\n",
        "  for sample in tqdm(data, desc = \"Generating Average Embeddings\"):\n",
        "    e = embeddings[[images.tolist().index(c) for c in [i for i in images if sample in i]]]\n",
        "    averaged_embeddings.append(e.mean(0))\n",
        "  return np.stack(averaged_embeddings)\n",
        "\n",
        "# Get the model's predictions.\n",
        "y_pred = model.predict(process_data_model2(X_eval))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "67f48de73d384bb69fe75e5858ab531f",
            "1601198dc6ad449ba9f06c5448e4cb68",
            "9541eb4895b54baf8ad409bd24b2557c",
            "172d7fea325843728dd71d6429aa19ab",
            "ed74296730f14f9db94a44db1f5a7085",
            "1be4431b23584b0296e10aadbdd71a45",
            "dab158b2693b4969be3476651585efb4",
            "81131ac9f0784292a28bd954dd8c6a82",
            "cd3cdd97d5fe436cbaea90ab03aeb6bc",
            "aff39b4a3b164b3e91f1f78dca255607",
            "7666dab312794d8c8a57f4a2012a2c2e"
          ]
        },
        "id": "xs5FTEk6wO7P",
        "outputId": "95522f7c-02d0-4d06-fdc8-6eab0da70c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating Average Embeddings:   0%|          | 0/24 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67f48de73d384bb69fe75e5858ab531f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the evaluation score."
      ],
      "metadata": {
        "id": "q25FMO5WwqyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"Ground Truth:\\t\\t\", y_eval)\n",
        "print(\"Predictions:\\t\\t\", y_pred)\n",
        "print(\"Mean Squared Error:\\t\", mean_squared_error(y_eval, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehq6LmA0wsiV",
        "outputId": "6eddee6b-a344-439b-9e41-c77104847457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth:\t\t [0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 1 1 0]\n",
            "Predictions:\t\t [1 0 0 1 0 0 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 0]\n",
            "Mean Squared Error:\t 0.125\n"
          ]
        }
      ]
    }
  ]
}